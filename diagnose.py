from datetime import datetime
import streamlit as st
import torch
from PIL import Image
import json
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from MedMamba import VSSM
from io import BytesIO
import base64
from LLM import DiagnosisExplainer
from torchvision import transforms

# è®¾å¤‡é…ç½®
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# æ¨¡å‹é…ç½®
@st.cache_resource
def load_model():
    model = VSSM(depths=[2, 2, 12, 2], dims=[128,256,512,1024], num_classes=8).to(device)
    model.load_state_dict(torch.load('medmambaNet.pth', map_location=device))
    model.eval()
    return model.to(device)

# é¢„å¤„ç†ç®¡é“
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# åŠ è½½ç±»åˆ«æ ‡ç­¾
with open('class_indices.json', 'r') as f:
    class_indict = json.load(f)
labels = [v for _, v in class_indict.items()]

# ç•Œé¢å¸ƒå±€
st.set_page_config(page_title="Kvasirç—…ç†è¯Šæ–­ç³»ç»Ÿ", layout="wide")
st.title("Kvasirå†…é•œå›¾åƒæ™ºèƒ½è¯Šæ–­ç³»ç»Ÿ")

# åˆå§‹åŒ–LLMè§£é‡Šå™¨
from LLM import DiagnosisExplainer
if 'explainer' not in st.session_state:
    st.session_state.explainer = DiagnosisExplainer("6b7a963f-0952-4338-8e3e-29460040f0bf")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'model' not in st.session_state:
    try:
        st.session_state.model = load_model()
        st.success("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

# ä¾§è¾¹æ è¯´æ˜
with st.sidebar:
    st.header("ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. ä¸Šä¼ å†…é•œå›¾åƒï¼ˆJPEG/PNGæ ¼å¼ï¼‰
    2. ç³»ç»Ÿè‡ªåŠ¨è¿›è¡Œç—…ç†åˆ†æ
    3. æŸ¥çœ‹è¯Šæ–­ç»“æœå’Œç½®ä¿¡åº¦
    4. ç‚¹å‡»"ç”Ÿæˆè¯¦ç»†è§£é‡Š"è·å–AIåˆ†æ
    """)
    st.divider()
    if st.button("ğŸ› ï¸ ç³»ç»Ÿå¥åº·æ£€æŸ¥"):
        with st.status("æ‰§è¡Œå…¨é¢è¯Šæ–­...", expanded=True) as status:
            check_results = []
            
            # éªŒè¯æ ¸å¿ƒä¾èµ–
            try:
                import torch, streamlit, PIL, numpy
                check_results.append(("æ ¸å¿ƒä¾èµ–", "âœ… é€šè¿‡", f"Torch {torch.__version__}"))
            except ImportError as e:
                check_results.append(("æ ¸å¿ƒä¾èµ–", "âŒ å¤±è´¥", f"ç¼ºå¤±æ¨¡å—: {str(e)}"))

            # éªŒè¯æ¨¡å‹åŠ è½½
            try:
                model = load_model()
                check_results.append(("ç—…ç†æ¨¡å‹", "âœ… é€šè¿‡", f"å‚æ•°æ•°é‡: {len(list(model.parameters()))}"))
            except Exception as e:
                check_results.append(("ç—…ç†æ¨¡å‹", "âŒ å¤±è´¥", f"åŠ è½½é”™è¯¯: {str(e)}"))

            # éªŒè¯APIè¿æ¥
            try:
                explainer = DiagnosisExplainer("6b7a963f-0952-4338-8e3e-29460040f0bf")
                check_results.append(("AIè§£é‡ŠæœåŠ¡", "âœ… é€šè¿‡", "ç«¯ç‚¹å“åº”æ­£å¸¸"))
            except Exception as e:
                check_results.append(("AIè§£é‡ŠæœåŠ¡", "âŒ å¤±è´¥", f"è¿æ¥é”™è¯¯: {str(e)}"))

            # æ˜¾ç¤ºæ£€æŸ¥ç»“æœ
            status.update(label="è¯Šæ–­å®Œæˆ", state="complete")
            st.table(pd.DataFrame(check_results, columns=["æ¨¡å—", "çŠ¶æ€", "è¯¦æƒ…"]))

# ä¸»ç•Œé¢
uploaded_file = st.file_uploader("ä¸Šä¼ å†…é•œå›¾åƒ", type=["jpg", "jpeg", "png"])
col1, col2 = st.columns(2)

if uploaded_file is not None:
    try:
        # å›¾åƒé¢„å¤„ç†
        img = Image.open(uploaded_file).convert('RGB')
        input_tensor = transform(img).unsqueeze(0).to(device)
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            output = st.session_state.model(input_tensor)
            probs = torch.nn.functional.softmax(output, dim=1)[0] * 100

        # åˆå§‹åŒ–è§£é‡Šå™¨
        if 'explainer' not in st.session_state:
            try:
                st.session_state.explainer = DiagnosisExplainer("6b7a963f-0952-4338-8e3e-29460040f0bf")
            except Exception as e:
                st.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
                st.stop()  # ä½¿ç”¨st.stop()æ›¿ä»£éæ³•return
        
        with col1:
            st.image(img, caption="è¾“å…¥å›¾åƒ", use_container_width=True)
            
        with col2:
            # æ˜¾ç¤ºè¯Šæ–­ç»“æœ
            pred_idx = torch.argmax(probs).item()
            st.subheader(f"è¯Šæ–­ç»“æœ: {labels[pred_idx]}")
            st.metric(label="ç½®ä¿¡åº¦", value=f"{probs[pred_idx]:.1f}%")
        
        # å¢å¼ºç‰ˆç»“æœå±•ç¤º
        with st.expander("ğŸ“Š è¯¦ç»†è¯Šæ–­åˆ†æ", expanded=True):
            tab1, tab2 = st.tabs(["ç½®ä¿¡åº¦åˆ†å¸ƒ","ä¸´åºŠæŒ‡å—"])
            y_pos = np.arange(len(labels))
            with tab1:
                fig, ax = plt.subplots(figsize=(12, 6))
                ax.barh(y_pos, probs.cpu().numpy(), color='#1f77b4')
                plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
                ax.set_title("Probability")
                ax.set_yticks(y_pos)
                ax.set_yticklabels(labels)
                st.pyplot(fig)
                            
            with tab2:
                st.markdown("""
                **ä¸´åºŠå¤„ç†æŒ‡å—**
                - ç«‹å³å¤„ç†æŒ‡å¾: ç½®ä¿¡åº¦ >85%
                - å»ºè®®ä¼šè¯ŠèŒƒå›´: 50%-85%
                - å®šæœŸå¤æŸ¥å»ºè®®: <50%
                """) 
        
        # è‡ªåŠ¨ç”ŸæˆAIè§£é‡Š
        with st.spinner("AIåˆ†æä¸­..."):
            try:
                diagnosis = (labels[pred_idx], probs[pred_idx].item())
                # å°†ä¸Šä¼ å›¾ç‰‡è½¬æ¢ä¸ºbase64
                buffered = BytesIO()
                img.save(buffered, format="JPEG")
                image_base64 = base64.b64encode(buffered.getvalue()).decode()

                explanation = st.session_state.explainer.generate_explanation(diagnosis, image_base64)
                # åœ¨æ–°è¡Œå±…ä¸­æ˜¾ç¤ºæŠ¥å‘Šæ ‡é¢˜
                st.markdown("<h2 style='text-align: center;'>ç—…ç†åˆ†ææŠ¥å‘Š</h2>", unsafe_allow_html=True)

                # ä½¿ç”¨ Markdown è§£æå±•ç¤ºè§£é‡Šå†…å®¹
                st.markdown("""
                    <style>
                        .report-box {
                            border: 1px solid #e0e0e0;
                            border-radius: 10px;
                            padding: 20px;
                            margin: 20px 0;
                            background: #f8f9fa;
                        }
                    </style>
                """, unsafe_allow_html=True)

                with st.expander("ğŸ“‹ å®Œæ•´ç—…ç†æŠ¥å‘Š", expanded=True):
                    st.markdown(f"""
                        <div class="report-box">
                            {explanation.replace('\n', '<br>')}
                        </div>
                    """, unsafe_allow_html=True)
                    st.download_button("ä¸‹è½½å®Œæ•´æŠ¥å‘Š", explanation, file_name="diagnosis_report.md")
            except Exception as e:
                st.error(f"è§£é‡Šç”Ÿæˆå¤±è´¥: {str(e)}")
        
    except Exception as e:
        st.error(f"å¤„ç†é”™è¯¯: {str(e)}")

# æ·»åŠ æ¨¡å‹ä¿¡æ¯æŠ˜å æ 
with st.expander("æ¨¡å‹è¯¦ç»†ä¿¡æ¯"):
    st.markdown("""
    **æ¨¡å‹æ¶æ„å‚æ•°**
    - åŸºç¡€ç»´åº¦: [128, 256, 512, 1024]
    - æ·±åº¦é…ç½®: [2, 2, 12, 2]
    - åˆ†ç±»å¤´: 8ç±»åˆ«
    """)
    if st.button("éªŒè¯æ¨¡å‹æƒé‡"):
        try:
            state_dict = torch.load('medmambaNet.pth')
            st.write(f"æƒé‡æ–‡ä»¶åŒ…å« {len(state_dict)} ä¸ªå‚æ•°")
        except:
            st.error("æƒé‡æ–‡ä»¶åŠ è½½å¤±è´¥")

# æ·»åŠ é¡µè„š
st.divider()
st.caption("åŒ»ç–—è¯Šæ–­ç³»ç»Ÿ - åŸºäºMedMambaæ¶æ„ ç‰ˆæœ¬1.0")

import streamlit as st
import torch
from PIL import Image
import json
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from io import BytesIO
import base64
from torchvision import transforms
import cv2
import torch.nn.functional as F
from grad_cam import GradCAM
from MedMamba import SS_Conv_SSM, SparseAttention, SEBlock
from fpdf import FPDF
import tempfile
from matplotlib.font_manager import FontProperties
import uuid

# --- Configuration ---
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# --- Page Title ---
st.title("AIç—…ç†è¯Šæ–­ç³»ç»Ÿ")

# --- Check if Model and Explainer are Loaded ---
if 'model' not in st.session_state or not st.session_state.get('model_loaded', False):
    st.error("æ¨¡å‹æ²¡æœ‰å®ŒæˆåŠ è½½ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ä»¥åŠç³»ç»Ÿé¦–é¡µçš„ä½“ç»ŸçŠ¶æ€")
    st.stop() 

if 'explainer' not in st.session_state or not st.session_state.get('explainer_loaded', False):
    st.warning("å¤§è¯­è¨€æ¨¡å‹æ²¡æœ‰å®ŒæˆåŠ è½½ï¼Œè¯Šæ–­ä¾ç„¶æœ‰æ•ˆä½†æ˜¯ä¸ä¼šæœ‰ç—…ç†è§£é‡Š")

def tensor_to_image(tensor):
    tensor = tensor.squeeze().cpu()
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    tensor = tensor * std + mean  # Denormalize
    tensor = tensor.clamp(0, 1)
    return tensor.permute(1, 2, 0).numpy()  # [H, W, 3], float32 [0,1]

def create_overlay(input_img, heatmap, alpha=0.5):
    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)  # Normalize to [0,1]
    heatmap_color = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)
    heatmap_color = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB) / 255.0
    overlay = input_img * (1 - alpha) + heatmap_color * alpha
    return np.clip(overlay, 0, 1)

# --- Preprocessing Pipeline ---
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# --- Load Class Labels ---
try:
    with open('class_indices.json', 'r') as f:
        class_indict = json.load(f)
    labels = [v for _, v in class_indict.items()]
except FileNotFoundError:
    st.error("å‘ç”Ÿé”™è¯¯: 'æœªæ‰¾åˆ° â€œclass_indices.jsonâ€ æ–‡ä»¶ã€‚æ— æ³•å°†é¢„æµ‹ç»“æœæ˜ å°„åˆ°æ ‡ç­¾ä¸Šã€‚")
    st.stop()
except Exception as e:
    st.error(f"åœ¨åŠ è½½æ ‡ç­¾å“ˆå¸Œè¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    st.stop()

# --- Sidebar for Diagnosis Page ---
with st.sidebar:
    st.header("ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. ä¸Šä¼ å†…çª¥é•œå›¾åƒ(JPEG/PNGæ ¼å¼)
    2. ç³»ç»Ÿå°†è‡ªåŠ¨è¿›è¡Œç—…ç†åˆ†æ
    3. æŸ¥çœ‹è¯Šæ–­ç»“æœåŠç½®ä¿¡åº¦è¯„åˆ†
    4. å±•å¼€ä¸‹æ–¹åŒºåŸŸæŸ¥çœ‹è¯¦ç»†åˆ†æå’ŒAIç”ŸæˆæŠ¥å‘Š
    """)
    st.divider()
    if st.button("ğŸ› ï¸ ç³»ç»Ÿå¥åº·æ£€æŸ¥"):
        with st.status("æ‰§è¡Œæ£€æŸ¥ä¸­", expanded=True) as status:
            check_results = []
            try:
                import torch, PIL, numpy
                check_results.append(("æ ¸å¿ƒåº“", "âœ… å®Œæˆ", f"Torch {torch.__version__}"))
            except ImportError as e:
                check_results.append(("æ ¸å¿ƒåº“", "âŒ å¤±è´¥", f"Missing: {str(e)}"))
            if 'model' in st.session_state and st.session_state.get('model_loaded', False):
                 check_results.append(("ç—…ç†æ¨¡å‹", "âœ… åŠ è½½å®Œæˆ", f"è®¾å¤‡: {device}"))
            else:
                 check_results.append(("ç—…ç†æ¨¡å‹", "âŒ æœªèƒ½åŠ è½½", "æ£€æŸ¥é¦–é¡µçŠ¶æ€"))
            if 'explainer' in st.session_state and st.session_state.get('explainer_loaded', False):
                 check_results.append(("AIè¯Šæ–­", "âœ… åˆå§‹åŒ–", "å®Œæˆ"))
            else:
                 check_results.append(("AIè¯Šæ–­", "âŒ åˆå§‹åŒ–å¤±è´¥", "æ£€æŸ¥ä¸»é¡µçŠ¶æ€ / API å¯†é’¥"))
            status.update(label="Diagnostics Complete", state="complete")
            st.table(pd.DataFrame(check_results, columns=["ç»„ä»¶", "çŠ¶æ€", "è¯¦æƒ…"]))

# --- Main Interface ---
uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"])
col1, col2 = st.columns(2)

if uploaded_file is not None:
    try:
        # Image Preprocessing
        img = Image.open(uploaded_file).convert('RGB')
        input_tensor = transform(img).unsqueeze(0).to(device)

        # Set up attention capture
        sparse_maps = []
        se_weights = []
        se_attn_maps = []  # æ–°å¢ï¼šå­˜å‚¨ SE ç©ºé—´æ³¨æ„åŠ›å›¾

        # Hook functions for attention
        def save_sparse(module, inp, out):
            x = inp[0]  # [B, C, H, W]
            B, C, H, W = x.shape
            pad = module.window_size // 2
            q = module.q_proj(x).view(B, module.num_heads, module.head_dim, H, W)
            k = module.k_proj(x).view(B, module.num_heads, module.head_dim, H, W)
            k_pad = F.pad(k, (pad, pad, pad, pad))
            k_win = (k_pad
                     .unfold(3, module.window_size, 1)
                     .unfold(4, module.window_size, 1)
                     .contiguous()
                     .view(B, module.num_heads, module.head_dim, H, W, -1))
            attn = (q.unsqueeze(-1) * k_win).sum(dim=2) * module.scale
            attn = attn.softmax(dim=-1)
            sparse_maps.append(attn[0, 0].mean(dim=-1).cpu())  # [H, W]

        def save_se(module, inp, out):
            x = inp[0]  # [B, C, H, W]
            b, c, h, w = x.shape
            y = module.avg_pool(x).view(b, c)  # [B, C]
            wts = module.fc(y).cpu()  # [B, C]
            se_weights.append(wts[0])  # [C]
            se_attn_maps.append(out.mean(dim=1)[0].cpu())  # [H, W]

        # Register hooks
        model = st.session_state.model
        handles = []
        for m in model.modules():
            if isinstance(m, SparseAttention):
                handles.append(m.register_forward_hook(save_sparse))
            elif isinstance(m, SEBlock):
                handles.append(m.register_forward_hook(save_se))

        # Model Inference
        with torch.no_grad():
            output = model(input_tensor)
            probs = torch.nn.functional.softmax(output, dim=1)[0] * 100

        # Remove hooks
        for h in handles:
            h.remove()

        # Display Input Image
        with col1:
            st.image(img, caption="è¾“å…¥å›¾åƒ", use_container_width=True)

        # Display Diagnosis Result
        with col2:
            pred_idx = torch.argmax(probs).item()
            pred_label = labels[pred_idx]
            pred_conf = probs[pred_idx].item()
            st.subheader(f"è¯Šæ–­ç»“æœï¼š{labels[pred_idx]}")
            st.metric(label="ç½®ä¿¡åº¦", value=f"{probs[pred_idx]:.1f}%")

        # Enhanced Results Display
        with st.expander("ğŸ“Š è¯¦ç»†è¯Šæ–­åˆ†æ", expanded=True):
            tab1, tab2 = st.tabs(["ç½®ä¿¡åº¦åˆ†å¸ƒ", "ä¸´åºŠå»ºè®®"])
            y_pos = np.arange(len(labels))
            with tab1:
                font = FontProperties(fname='SimHei.ttf')
                fig_conf, ax_conf = plt.subplots(figsize=(10, 5))
                ax_conf.barh(y_pos, probs.cpu().numpy(), align='center')
                ax_conf.set_yticks(y_pos)
                ax_conf.set_yticklabels(labels, fontproperties=font)
                ax_conf.invert_yaxis()
                ax_conf.set_xlabel("å¯ä¿¡åº¦ (%)", fontproperties=font)
                ax_conf.set_title("ä¸åŒç±»åˆ«çš„ç½®ä¿¡åº¦", fontproperties=font)
                st.pyplot(fig_conf)

            with tab2:
                st.markdown("""
                **ä¸´åºŠå¤„ç†å»ºè®®ï¼ˆç¤ºä¾‹æŒ‡å—ï¼‰**
                * **é«˜ç½®ä¿¡åº¦ (>85%):** å»ºè®®æ ¹æ®å‘ç°ç«‹å³é‡‡å–è¡ŒåŠ¨æˆ–ä¼šè¯Š
                * **ä¸­ç½®ä¿¡åº¦ (50%-85%):** å»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥æˆ–ä¸“ç§‘ä¼šè¯Š
                * **ä½ç½®ä¿¡åº¦ (<50%):** å»ºè®®è§‚å¯Ÿéšè®¿
                * *å…è´£å£°æ˜ï¼šæœ¬æŒ‡å—ä»…ä¸ºç¤ºä¾‹ï¼Œä¸æ„æˆåŒ»ç–—å»ºè®®*
                """)

        # Get 224x224 input image for overlays
        input_img = tensor_to_image(input_tensor)

        # Generate CAM
        try:
            model.eval()
            last_block = model.layers[-1].blocks[-1]
            target_layer = last_block.conv33conv33conv11[7]
            gradcam = GradCAM(model, target_layer)
            cam_gray = gradcam.forward(input_tensor, class_idx=pred_idx)
            cam_overlay = create_overlay(input_img, cam_gray)
        except Exception as e:
            st.error(f"ç”ŸæˆCAMå¤±è´¥: {str(e)}")
            cam_overlay = None

        # Generate sparse attention map
        attn_overlay = None
        if sparse_maps:
            try:
                attn0 = sparse_maps[-1]  # ä½¿ç”¨æœ€åä¸€ä¸ªæ³¨æ„åŠ›å›¾
                attn0 = F.interpolate(attn0.unsqueeze(0).unsqueeze(0), size=(224, 224),
                                      mode='bilinear', align_corners=False)[0, 0].numpy()
                attn_overlay = create_overlay(input_img, attn0)
            except Exception as e:
                st.error(f"æ³¨æ„åŠ›å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")

        # Generate SE attention map
        se_attn_map = se_attn_maps[-1] if se_attn_maps else None
        if se_attn_map is not None:
            try:
                se_attn_map = F.interpolate(se_attn_map.unsqueeze(0).unsqueeze(0), size=(224, 224),
                                            mode='bilinear', align_corners=False)[0, 0]
                se_attn_heatmap = (se_attn_map - se_attn_map.min()) / (se_attn_map.max() - se_attn_map.min() + 1e-8)
                se_attn_overlay = create_overlay(input_img, se_attn_heatmap.numpy())
            except Exception as e:
                st.error(f"SEæ³¨æ„åŠ›å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")
                se_attn_overlay = None
        else:
            se_attn_overlay = None

        # Interpretability Section
        with st.expander("ğŸ” æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ", expanded=False):
            cols = st.columns(3)
            if cam_overlay is not None:
                with cols[0]:
                    st.subheader("ç±»åˆ«æ¿€æ´»å›¾ (CAM)")
                    st.image(cam_overlay, caption="CAMå¯è§†åŒ–å åŠ æ•ˆæœï¼ˆå¤„ç†åçš„224x224å›¾åƒï¼‰", use_container_width=True)
            with cols[1]:
                if attn_overlay is not None:
                    st.subheader("ç¨€ç–æ³¨æ„åŠ›å åŠ å›¾")
                    st.image(attn_overlay, caption="ç¨€ç–æ³¨æ„åŠ›å›¾", use_container_width=True)
            if se_attn_overlay is not None:
                with cols[2]:
                    st.subheader("SEæ³¨æ„åŠ›å åŠ å›¾")
                    st.image(se_attn_overlay, caption="SEæ³¨æ„åŠ›å›¾å åŠ ", use_container_width=True)
                st.subheader("SEæ³¨æ„åŠ›çƒ­åŠ›å›¾")
                fig_se, ax_se = plt.subplots(figsize=(5, 5))
                im_se = ax_se.imshow(se_attn_heatmap.numpy(), cmap='jet')
                fig_se.colorbar(im_se)
                ax_se.axis('off')
                st.pyplot(fig_se)    
            if se_weights:
                try:
                    w = se_weights[-1].numpy()  # ä½¿ç”¨æœ€åä¸€ä¸ª SE å—çš„æƒé‡
                    font = FontProperties(fname='SimHei.ttf')
                    fig, ax = plt.subplots(figsize=(8, 2))
                    ax.bar(range(len(w)), w)
                    ax.set_title("SEé€šé“æƒé‡", fontproperties=font)
                    ax.set_xlabel("é€šé“", fontproperties=font)
                    ax.set_ylabel("æƒé‡", fontproperties=font)
                    st.pyplot(fig)
                except Exception as e:
                    st.error(f"æ— æ³•æ˜¾ç¤ºé€šé“æƒé‡: {str(e)}")

        # AI Explanation Section
        if 'explainer' in st.session_state and st.session_state.get('explainer_loaded', False):
            st.markdown("---")
            st.subheader("ğŸ¤– å¤§è¯­è¨€æ¨¡å‹è¾…åŠ©è¯Šæ–­")
            with st.spinner("å¤§è¯­è¨€æ¨¡å‹è¯Šæ–­ä¸­..."):
                try:
                    diagnosis = (labels[pred_idx], probs[pred_idx].item())
                    buffered = BytesIO()
                    img.save(buffered, format="JPEG")
                    image_base64 = base64.b64encode(buffered.getvalue()).decode()
                    explanation = st.session_state.explainer.generate_explanation(diagnosis, image_base64)
                    st.markdown("""
                        <style>
                            .report-box {
                                border: 1px solid #e0e0e0;
                                border-radius: 8px;
                                padding: 15px;
                                margin-top: 10px;
                                background-color: #f8f9fa;
                                font-family: sans-serif;
                                line-height: 1.6;
                            }
                        </style>
                    """, unsafe_allow_html=True)
                    st.markdown(f"""
                        <div class="report-box">
                            {explanation.replace('\n', '<br>')}
                        </div>
                    """, unsafe_allow_html=True)
                    
                    # PDF Generation
                    buf_input = BytesIO()
                    img.save(buf_input, format="PNG")
                    buf_input.seek(0)
                    buf_conf = BytesIO()
                    fig_conf.savefig(buf_conf, format="PNG", bbox_inches='tight')
                    buf_conf.seek(0)
                    buf_cam = BytesIO()
                    if cam_overlay is not None:
                        cam_img = Image.fromarray((cam_overlay * 255).astype('uint8'))
                        cam_img.save(buf_cam, format="PNG")
                        buf_cam.seek(0)
                    def write_tmp(buf, suffix=".png"):
                        tmp = tempfile.NamedTemporaryFile(suffix=suffix, delete=False)
                        tmp.write(buf.getvalue())
                        tmp.flush()
                        return tmp.name
                    input_path = write_tmp(buf_input)
                    conf_path = write_tmp(buf_conf)
                    cam_path = write_tmp(buf_cam) if cam_overlay is not None else None
                    pdf = FPDF(format='A4')
                    pdf.add_page()
                    pdf.set_margins(10, 10, 10)
                    pdf.set_auto_page_break(auto=True, margin=10)
                    pdf.add_font('SimHei', '', 'SimHei.ttf', uni=True)
                    pdf.set_font("SimHei", "", 14)
                    pdf.cell(0, 8, "ç—…ç†è¯Šæ–­å®Œæ•´æŠ¥å‘Š", ln=True, align="C")
                    pdf.ln(6)
                    img_w = 100
                    pdf.set_font("SimHei", "", 12)
                    pdf.cell(0, 6, "1. ä¸Šä¼ åŸå›¾", ln=True)
                    pdf.image(input_path, x=(pdf.w - img_w)/2, w=img_w)
                    pdf.ln(2)
                    pdf.set_font("SimHei", "", 10)
                    pdf.cell(0, 5, "å›¾1: ä¸Šä¼ çš„åŸå§‹ç—…ç†å›¾åƒ", align="C")
                    pdf.ln(4)
                    pdf.set_font("SimHei", "", 12)
                    pdf.cell(0, 6, "2. Grad-CAM å¯è§†åŒ–", ln=True)
                    pdf.image(cam_path, x=(pdf.w - img_w)/2, w=img_w)
                    pdf.ln(2)
                    pdf.set_font("SimHei", "", 10)
                    pdf.cell(0, 5, "å›¾2: Grad-CAM å¯è§†åŒ–ç»“æœ", align="C")
                    pdf.ln(4)
                    pdf.set_font("SimHei", "", 12)
                    pdf.cell(0, 6, "3. ç½®ä¿¡åº¦åˆ†å¸ƒ", ln=True)
                    if cam_path:
                        pdf.image(conf_path, x=(pdf.w - img_w)/2, w=img_w)
                        pdf.ln(2)
                        pdf.set_font("SimHei", "", 10)
                        pdf.cell(0, 5, "å›¾3: ç½®ä¿¡åº¦åˆ†å¸ƒå›¾", align="C")
                        pdf.ln(4)
                    pdf.set_font("SimHei", "", 12)
                    pdf.cell(0, 6, "4. è¯Šæ–­ç»“æœ", ln=True)
                    pdf.set_font("SimHei", "", 10)
                    pdf.multi_cell(0, 5, f"ç±»åˆ«ï¼š{pred_label}\nç½®ä¿¡åº¦ï¼š{pred_conf:.1f}%")
                    pdf.ln(4)
                    pdf.set_font("SimHei", "", 12)
                    pdf.cell(0, 6, "5. AI ç”Ÿæˆçš„ç—…ç†æŠ¥å‘Šï¼ˆæ‘˜è¦ï¼‰", ln=True)
                    pdf.set_font("SimHei", "", 10)
                    for line in explanation.split("\n")[:8]:
                        pdf.multi_cell(0, 5, line)
                    pdf_bytes = pdf.output(dest='S')
                    pdf_buffer = BytesIO(pdf_bytes.encode('latin-1'))
                    pdf_buffer.seek(0)
                    st.download_button("â¬‡ï¸ Download PDF", data=pdf_buffer, file_name=f"{pred_label}.pdf", mime="application/pdf")
                except Exception as e:
                    st.error(f"Failed to generate AI explanation: {str(e)}")
        else:
            st.info("AI explanation service is not available.")

    except Exception as e:
        st.error(f"An error occurred during image processing or diagnosis: {str(e)}")
        st.exception(e)

# --- Model Information Expander ---
with st.expander("æ¨¡å‹ç³»ç»Ÿæ¶ˆæ¯"):
    st.markdown("""
    **æ¨¡å‹æ¶æ„:** NylonFuseNet
    * **æ·±åº¦:** [2, 2, 12, 2]
    * **ç»´åº¦:** [128, 256, 512, 1024]
    * **åˆ†ç±»:** 8
    * **æ•°æ®é›†:** Kvasir V2
    """)
    if st.button("éªŒè¯æ¨¡å‹çŠ¶æ€"):
        if 'model' in st.session_state:
            st.write(f"è®¾å¤‡ä¸Šçš„æ¨¡å‹: `{next(st.session_state.model.parameters()).device}`")
            st.write(f"å‚æ•°: {sum(p.numel() for p in st.session_state.model.parameters())}")
        else:
            st.error("æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹")

# --- Footer ---
st.divider()
st.caption("Kvasir Pathology Diagnosis System - Version 1.0")